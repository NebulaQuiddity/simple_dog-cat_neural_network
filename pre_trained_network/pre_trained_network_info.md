# Network information
- Shape (Excluding input layer): [100, 50, 20, 10]
- Activation Functions:
  - Hidden layers: Leaky Relu
  - Output layer: Sigmoid
- Epsilon: 0.01
